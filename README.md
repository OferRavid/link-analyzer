# ğŸ”— Link Analyzer

## ğŸ“Œ Description
**Link Analyzer** is a JavaScript application that generates an "internal links" report for any website by crawling its pages. The program extracts and normalizes URLs found on the given web page and follows internal links to analyze the structure of the website.

## âœ¨ Features
âœ… Crawls web pages and extracts internal links  
âœ… Normalizes URLs for consistency  
âœ… Handles both relative and absolute URLs  
âœ… Fetches and parses HTML content  
âœ… Includes Jest tests for key functionalities  

## ğŸ“¥ Installation
### Prerequisites
Ensure you have [Node.js](https://nodejs.org/) installed on your system.

### Steps
- 1ï¸âƒ£ Clone the repository:
   ```sh
   git clone https://github.com/OferRavid/link-analyzer.git
   ```
- 2ï¸âƒ£ Navigate to the project directory:
   ```sh
   cd link-analyzer
   ```
- 3ï¸âƒ£ Install dependencies:
   ```sh
   npm install
   ```

## ğŸŒ Usage
To run the web crawler, use:
```sh
npm start <URL>
```
Example:
```sh
npm start https://example.com
```

## ğŸ›  Running Tests
This project includes unit tests using **Jest**. To execute tests, run:
```sh
npm test
```

## ğŸ“ Project Structure
```
ğŸ“‚ link-analyzer/
â”œâ”€â”€ ğŸ•·ï¸ crawl.js        # Core crawling and URL processing logic
â”œâ”€â”€ ğŸ§ª crawl.test.js   # Jest test cases for URL normalization and extraction
â”œâ”€â”€ ğŸ”— main.js         # Entry point for the application
â”œâ”€â”€ ğŸ“¦ package.json    # Project configuration and dependencies
â””â”€â”€ ğŸ“– README.md       # Project documentation
```

## ğŸ¤ Contributing
Contributions are welcome! If youâ€™d like to improve this project, feel free to fork the repository and submit a pull request. ğŸ’¡

## ğŸ“œ License
This project is licensed under the **MIT License**.

## ğŸ‘¤ Author
**Ofer Ravid**

